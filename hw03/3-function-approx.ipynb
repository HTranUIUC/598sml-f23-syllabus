{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Approximating a 1D function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a nonlinear function f(x) that we want to approximate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return torch.where(x < 0, torch.cos(x/3), 0.5*torch.sin(8*x - 1.5*x**2) + 0.5*x - 0.1*x**2)\n",
    "\n",
    "x = torch.linspace(-3, 6, 200)\n",
    "y = f(x)\n",
    "plt.plot(x.numpy(), y.numpy(), 'b')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use a fully-connected NN to approximate the function $f(x)$ defined above.\n",
    "\n",
    "2. Use tensorboard (or another logging system) to track learning progress by logging the loss function.\n",
    "\n",
    "3. Log a figure to tensorboard to visualize learning.\n",
    "\n",
    "4. Log hyperparameters to tensorboard as part of workflow/experiment management.\n",
    "\n",
    "5. What hyperparameters did you need to get a good function approximation? Specify at least the NN architecture (number of layers, layer width, layer type) and the optimizer parameters (learning rate, optimizer type). How many total parameters did your model have and how does this compare to the number of training samples?\n",
    "\n",
    "6. Make a movie of how the model predictions evolve as the optimization proceeds.\n",
    "\n",
    "7. Generate a different set of samples from the true function for use as a testing set and plot the testing error as well as the training error during training. Do you see any sign of overfitting?\n",
    "\n",
    "8. Experiment with mini-batches, where a random subset of the training data is used at each optimization step. Does this help speed up learning on this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters and hyper-parameters\n",
    "\n",
    "The NN weights and biases are called the _parameters_ of the network.\n",
    "\n",
    "The NN layer widths, number of layers, optimizer learning rate, etc., are called _hyper-parameters_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
