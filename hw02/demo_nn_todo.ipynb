{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528b9ec8-46b4-452c-bddb-5961f8ca98c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fb61bd-8646-4744-ab8c-90c1171cba23",
   "metadata": {},
   "source": [
    "### Define the recursive gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fed1fe-eeb1-499a-9ed5-bc95fa222241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradients(variable):\n",
    "    \"\"\" Compute the first derivatives of `variable` \n",
    "    with respect to child variables.\n",
    "    \"\"\"\n",
    "    gradients = defaultdict(lambda: 0)\n",
    "    \n",
    "    def compute_gradients(variable, path_value):\n",
    "        for child_variable, local_gradient in variable.local_gradients:\n",
    "            # \"Multiply the edges of a path\":\n",
    "            value_of_path_to_child = path_value * local_gradient\n",
    "    \n",
    "            # \"Add together the different paths\":\n",
    "            gradients[child_variable] += value_of_path_to_child\n",
    "            \n",
    "            # recurse through graph:\n",
    "            compute_gradients(child_variable, value_of_path_to_child)\n",
    "    \n",
    "    compute_gradients(variable, path_value=1)\n",
    "    # (path_value=1 is from `variable` differentiated w.r.t. itself)\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dea9d59-a140-4b55-abb5-d42cd9ee8db3",
   "metadata": {},
   "source": [
    "### The Variable\n",
    "\n",
    "Add functionality for subtraction and division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5352326-5bcb-40a2-a865-b5d9d78d35fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Variable:\n",
    "    def __init__(self, value, local_gradients=[]):\n",
    "        self.value = value\n",
    "        self.local_gradients = local_gradients\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        return add(self, other)\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        return mul(self, other)\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        return add(self, neg(other))\n",
    "\n",
    "    def __truediv__(self, other):\n",
    "        return mul(self, inv(other))\n",
    "    \n",
    "def add(a, b):\n",
    "    value = a.value + b.value    \n",
    "    local_gradients = (\n",
    "        (a, 1),\n",
    "        (b, 1)\n",
    "    )\n",
    "    return Variable(value, local_gradients)\n",
    "\n",
    "def mul(a, b):\n",
    "    value = a.value * b.value\n",
    "    local_gradients = (\n",
    "        (a, b.value),\n",
    "        (b, a.value)\n",
    "    )\n",
    "    return Variable(value, local_gradients)\n",
    "\n",
    "def neg(a):\n",
    "    # TODO\n",
    "    return Variable(value, local_gradients)\n",
    "\n",
    "def inv(a):\n",
    "    # TODO\n",
    "    return Variable(value, local_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3a1f1f-726d-4c89-81ac-1383f4da2d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(a, b):\n",
    "    return (a / b - a) * (b / a + a + b) * (a - b)\n",
    "\n",
    "a = Variable(230.3)\n",
    "b = Variable(33.2)\n",
    "y = f(a, b)\n",
    "\n",
    "gradients = get_gradients(y)\n",
    "\n",
    "print(\"The partial derivative of y with respect to a =\", gradients[a])\n",
    "print(\"The partial derivative of y with respect to b =\", gradients[b])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b429ea80-69ee-41b9-aadc-f24ad6e1bfd5",
   "metadata": {},
   "source": [
    "### Verification\n",
    "\n",
    "How would you test whether this is correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434f7d4e-c37b-425b-ae3b-7507693a8988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09fce68b-8a1b-48d1-8ed6-ab9665958c29",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "Add functions for `sin` `exp` and `log` (using numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0627fb95-a13a-4e95-83fe-b12a824c376e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09348060-475a-485d-a8ef-06321f63d9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert NumPy array into array of Variable objects:\n",
    "to_var = np.vectorize(lambda x : Variable(x))\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "def update_weights(weights, gradients, lrate):\n",
    "    for _, weight in np.ndenumerate(weights):\n",
    "        weight.value -= lrate * gradients[weight]\n",
    "\n",
    "input_size = 50\n",
    "output_size = 10\n",
    "lrate = 0.001\n",
    "\n",
    "x = to_var(np.random.random(input_size))\n",
    "y_true = to_var(np.random.random(output_size))\n",
    "weights = to_var(np.random.random((input_size, output_size)))\n",
    "\n",
    "loss_vals = []\n",
    "for i in range(100):\n",
    "    y_pred = np.dot(x, weights)\n",
    "    loss = np.sum((y_true - y_pred) * (y_true - y_pred))\n",
    "    loss_vals.append(loss.value)\n",
    "    gradients = get_gradients(loss)\n",
    "    update_weights(weights, gradients, lrate)\n",
    "\n",
    "plt.plot(loss_vals)\n",
    "plt.xlabel(\"Time step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Single linear layer learning\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
